# ç®—æ³•æ¥å£ï¼šè´Ÿè´£è·å–yoloæ£€æµ‹æ¨¡å‹çš„ç»“æœ
import threading
import time
import numpy as np
import logging
from ultralytics import YOLO
import cv2
import pathlib

logging.basicConfig(level=logging.INFO)


class DroneDetector:
    """æ— äººæœºæ£€æµ‹ç®—æ³•ç±» - ä½¿ç”¨YOLOè¿›è¡Œç›®æ ‡æ£€æµ‹"""

    def __init__(self, state, data_processor, model_path="best.pt"):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            state: ç³»ç»ŸçŠ¶æ€å¯¹è±¡
            data_processor: æ•°æ®å¤„ç†å™¨å¯¹è±¡
            model_path: YOLOæ¨¡å‹è·¯å¾„
        """
        self.state = state
        self.data_processor = data_processor
        self.model_path = model_path

        # çº¿ç¨‹ç®¡ç†
        self.detect_thread = None
        self.detection_lock = threading.Lock()  # ä¿æŠ¤æ£€æµ‹ç»“æœå›¾åƒ

        # æ£€æµ‹ç»“æœå›¾åƒï¼ˆå¸¦æ¡†çš„RGBå›¾åƒï¼‰
        self.detection_image = None  # shape: (height, width, 3), uint8

        # æ£€æµ‹ç»“æœä¿¡æ¯
        self.detection_results = []  # å­˜å‚¨æ£€æµ‹æ¡†ä¿¡æ¯
        self.detection_count = 0  # æ£€æµ‹æ¬¡æ•°
        self.last_detection_time = 0  # ä¸Šæ¬¡æ£€æµ‹æ—¶é—´

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_detections = 0  # æ€»æ£€æµ‹æ¬¡æ•°
        self.total_objects = 0  # æ€»æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°
        self.fps = 0.0  # æ£€æµ‹å¸§ç‡
        # åŠ è½½YOLOæ¨¡å‹
        # è·å–ç®—æ³•å±‚ç»å¯¹è·¯å¾„ï¼Œyoloå’Œç®—æ³•å±‚åœ¨åŒä¸€ç›®å½•ä¸‹
        self.algorithm_path = pathlib.Path(__file__).parent.absolute()
        try:
            logging.info(f"æ­£åœ¨åŠ è½½YOLOæ¨¡å‹: {model_path}")
            model_path = str(self.algorithm_path / model_path)
            self.model = YOLO(model_path)
            logging.info("âœ“ YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
            # é¢„çƒ­æ¨¡å‹
            self._warmup_model()
        except Exception as e:
            logging.error(f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None

        # æ£€æµ‹å‚æ•°
        self.conf_threshold = self.state.conf_threshold  # ç½®ä¿¡åº¦é˜ˆå€¼
        self.iou_threshold = self.state.iou_threshold  # NMS IoUé˜ˆå€¼

        logging.info("ç®—æ³•å±‚åˆå§‹åŒ–å®Œæˆ")

    def _warmup_model(self):
        """é¢„çƒ­æ¨¡å‹ï¼ŒåŠ é€Ÿé¦–æ¬¡æ¨ç†"""
        if self.model is None:
            return

        try:
            logging.info("ğŸ”¥ é¢„çƒ­YOLOæ¨¡å‹...")
            # åˆ›å»ºå‡å›¾åƒè¿›è¡Œé¢„çƒ­
            dummy_image = np.random.randint(
                0,
                255,
                (self.data_processor.fft_length, self.data_processor.fft_length, 3),
                dtype=np.uint8,
            )

            # æ‰§è¡Œä¸€æ¬¡æ¨ç†ï¼ˆä¸ä¿å­˜ç»“æœï¼‰
            _ = self.model(dummy_image, verbose=False)
            logging.info("âœ“ æ¨¡å‹é¢„çƒ­å®Œæˆ")

        except Exception as e:
            logging.warning(f"æ¨¡å‹é¢„çƒ­å¤±è´¥: {e}ï¼Œå°†åœ¨é¦–æ¬¡æ£€æµ‹æ—¶åˆå§‹åŒ–")

    def start_detection(self):
        """å¯åŠ¨æ£€æµ‹çº¿ç¨‹"""
        if self.model is None:
            logging.error("YOLOæ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•å¯åŠ¨æ£€æµ‹")
            return

        if not self.detect_thread or not self.detect_thread.is_alive():
            self.state.detection_thread = True
            self.detect_thread = threading.Thread(
                target=self._detection_loop, daemon=True
            )
            self.detect_thread.start()
            logging.info("âœ“ æ£€æµ‹çº¿ç¨‹å·²å¯åŠ¨")

    def stop_detection(self):
        """åœæ­¢æ£€æµ‹çº¿ç¨‹"""
        self.state.detection_thread = False
        if self.detect_thread:
            self.detect_thread.join(timeout=3)
        logging.info("æ£€æµ‹çº¿ç¨‹å·²åœæ­¢")

    def _detection_loop(self):
        """æ£€æµ‹ä¸»å¾ªç¯ï¼ˆè¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ï¼‰"""
        logging.info("æ£€æµ‹å¾ªç¯å¼€å§‹è¿è¡Œ...")

        while self.state.detection_thread:
            try:
                start_time = time.time()

                # æ­¥éª¤1: ä»æ•°æ®å¤„ç†å±‚è·å–æœ€æ–°çš„RGBå›¾åƒ
                input_image = self.data_processor.get_waterfall_image()

                if input_image is None or input_image.size == 0:
                    logging.debug("æœªè·å–åˆ°æœ‰æ•ˆå›¾åƒï¼Œè·³è¿‡æ­¤æ¬¡æ£€æµ‹")
                    time.sleep(0.01)
                    continue

                # æ£€æŸ¥å›¾åƒæ ¼å¼
                if len(input_image.shape) != 3 or input_image.shape[2] != 3:
                    logging.warning(f"å›¾åƒæ ¼å¼ä¸æ­£ç¡®: {input_image.shape}")
                    time.sleep(0.01)
                    continue

                # æ­¥éª¤2: YOLOæ£€æµ‹

                results = self.model(
                    input_image,
                    conf=self.conf_threshold,
                    iou=self.iou_threshold,
                    verbose=False,  # å…³é—­è¯¦ç»†è¾“å‡º
                )

                # æ­¥éª¤3: å¤„ç†æ£€æµ‹ç»“æœ
                detection_info = []
                annotated_image = input_image.copy()

                if len(results) > 0:
                    result = results[0]  # å–ç¬¬ä¸€ä¸ªç»“æœ

                    # è·å–æ£€æµ‹æ¡†
                    boxes = result.boxes
                    if boxes is not None and len(boxes) > 0:
                        for box in boxes:
                            # æå–æ¡†ä¿¡æ¯
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = float(box.conf[0].cpu().numpy())
                            cls = int(box.cls[0].cpu().numpy())
                            class_name = self.model.names[cls]

                            detection_info.append(
                                {
                                    "bbox": [int(x1), int(y1), int(x2), int(y2)],
                                    "confidence": conf,
                                    "class_id": cls,
                                    "class_name": class_name,
                                }
                            )

                            # ç»˜åˆ¶æ£€æµ‹æ¡†
                            cv2.rectangle(
                                annotated_image,
                                (int(x1), int(y1)),
                                (int(x2), int(y2)),
                                (0, 255, 0),  # ç»¿è‰²æ¡†
                                2,
                            )

                            # ç»˜åˆ¶æ ‡ç­¾
                            label = f"{class_name} {conf:.2f}"
                            font = cv2.FONT_HERSHEY_SIMPLEX
                            font_scale = 0.5
                            thickness = 1

                            # è®¡ç®—æ–‡æœ¬å¤§å°
                            (text_width, text_height), baseline = cv2.getTextSize(
                                label, font, font_scale, thickness
                            )
                            # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                            cv2.rectangle(
                                annotated_image,
                                (int(x1), int(y1) - text_height - 10),
                                (int(x1) + text_width, int(y1)),
                                (0, 255, 0),
                                -1,  # å¡«å……
                            )

                            # ç»˜åˆ¶æ–‡æœ¬
                            cv2.putText(
                                annotated_image,
                                label,
                                (int(x1), int(y1) - 5),
                                font,
                                font_scale,
                                (0, 0, 0),  # é»‘è‰²æ–‡å­—
                                thickness,
                            )

                        self.total_objects += len(boxes)
                else:
                    # æ— æ£€æµ‹ç»“æœï¼Œä½¿ç”¨åŸå›¾
                    pass

                # æ­¥éª¤4: æ›´æ–°æ£€æµ‹ç»“æœï¼ˆä½¿ç”¨çº¿ç¨‹é”ï¼‰
                with self.detection_lock:
                    self.detection_image = annotated_image
                    self.detection_results = detection_info
                    self.detection_count += 1
                    self.last_detection_time = time.time()
                    self.total_detections += 1

                # è®¡ç®—å¤„ç†æ—¶é—´
                elapsed = time.time() - start_time
                self.fps = 1.0 / elapsed if elapsed > 0 else 0

                # æ— å»¶è¿Ÿï¼Œç«‹å³è¿›è¡Œä¸‹ä¸€æ¬¡æ£€æµ‹

            except Exception as e:
                logging.error(f"æ£€æµ‹å¼‚å¸¸: {e}", exc_info=True)
                time.sleep(0.1)  # å¼‚å¸¸æ—¶ç¨å¾®å»¶è¿Ÿ

        logging.info("æ£€æµ‹å¾ªç¯å·²é€€å‡º")

    # ==================== å¯¹å¤–æ¥å£ ====================

    def get_detection_image(self):
        """è·å–å¸¦æ£€æµ‹æ¡†çš„å›¾åƒï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Returns:
            np.ndarray or None: shape=(height, width, 3), dtype=uint8
        """
        with self.detection_lock:
            return (
                self.detection_image.copy()
                if self.detection_image is not None
                else None
            )

    def get_detection_results(self):
        """è·å–æ£€æµ‹ç»“æœä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Returns:
            list: æ£€æµ‹ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« bbox, confidence, class_id, class_name
        """
        with self.detection_lock:
            return self.detection_results.copy()

    def get_detection_stats(self):
        """è·å–æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Returns:
            dict: åŒ…å«æ£€æµ‹æ¬¡æ•°ã€ç›®æ ‡æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯
        """
        with self.detection_lock:
            return {
                "detection_count": self.detection_count,
                "total_detections": self.total_detections,
                "total_objects": self.total_objects,
                "last_detection_time": self.last_detection_time,
                "current_objects": len(self.detection_results),
                "fps": self.fps,
            }

    # ==================== é…ç½®æ¥å£ ====================

    def update_detection_parameters(self):
        """æ›´æ–°æ£€æµ‹å‚æ•°"""
        self.conf_threshold = self.state.conf_threshold
        self.iou_threshold = self.state.iou_threshold
        logging.info(
            f"æ£€æµ‹å‚æ•°å·²æ›´æ–°: conf_threshold={self.conf_threshold}, "
            f"iou_threshold={self.iou_threshold}"
        )
